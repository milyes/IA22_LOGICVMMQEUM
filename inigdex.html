<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Vision IA - Démo Temps Réel (IA22)</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.2/dist/ort.min.js"></script>
  <style>
    body { margin:0; font-family:Arial, sans-serif; background:#000; color:#0f0; }
    #container { position:relative; width:100vw; height:100vh; overflow:hidden; }
    #video, #canvas { position:absolute; top:0; left:0; width:100%; height:100%; object-fit:cover; }
    #canvas { pointer-events:none; }
    #info { position:absolute; top:10px; left:10px; background:rgba(0,0,0,0.6); padding:10px; border-radius:8px; font-size:14px; max-width:320px; }
    button { position:absolute; bottom:20px; left:50%; transform:translateX(-50%); padding:12px 24px; font-size:18px; background:#0f0; color:#000; border:none; border-radius:30px; cursor:pointer; z-index:10; }
    button:hover { background:#0fF; }
  </style>
</head>
<body>

<div id="container">
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="info">Chargement du modèle Vision IA... (YOLO11n)</div>
  <button id="startBtn">Démarrer Vision IA</button>
</div>

<script>
// === CONFIG ===
const MODEL_URL = './yolo11n.onnx';          // ← ton fichier ONNX ici
const INPUT_SIZE = 640;
const CONF_THRESHOLD = 0.35;
const NMS_THRESHOLD = 0.45;
const COCO_CLASSES = [
  'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat',
  'traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat',
  'dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack',
  'umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball',
  'kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket',
  'bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple',
  'sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair',
  'couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote',
  'keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book',
  'clock','vase','scissors','teddy bear','hair drier','toothbrush'
];

// === ÉLÉMENTS DOM ===
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const info = document.getElementById('info');
const startBtn = document.getElementById('startBtn');

let session = null;
let isRunning = false;

// === UTILS ===
function letterbox(imgWidth, imgHeight) {
  const scale = Math.min(INPUT_SIZE / imgWidth, INPUT_SIZE / imgHeight);
  const newW = Math.round(imgWidth * scale);
  const newH = Math.round(imgHeight * scale);
  const padW = INPUT_SIZE - newW;
  const padH = INPUT_SIZE - newH;
  return { scale, padLeft: padW/2, padTop: padH/2 };
}

function nms(boxes) {
  // Très basique – trie par score puis supprime les overlaps (IoU)
  boxes.sort((a,b) => b.score - a.score);
  const result = [];
  while (boxes.length > 0) {
    const box = boxes.shift();
    result.push(box);
    boxes = boxes.filter(b => {
      const ix = Math.max(box.xmin, b.xmin);
      const iy = Math.max(box.ymin, b.ymin);
      const iw = Math.min(box.xmax, b.xmax) - ix;
      const ih = Math.min(box.ymax, b.ymax) - iy;
      if (iw <= 0 || ih <= 0) return true;
      const inter = iw * ih;
      const union = (box.xmax-box.xmin)*(box.ymax-box.ymin) + (b.xmax-b.xmin)*(b.ymax-b.ymin) - inter;
      return inter / union < NMS_THRESHOLD;
    });
  }
  return result;
}

// === CHARGEMENT & INFÉRENCE ===
async function loadModel() {
  info.textContent = "Téléchargement du modèle Vision IA... (~6MB)";
  try {
    session = await ort.InferenceSession.create(MODEL_URL, {
      executionProviders: ['webgpu', 'wasm'],  // WebGPU >> WASM > WebGL
      graphOptimizationLevel: 'all'
    });
    info.textContent = "Modèle Vision IA chargé ! Prêt à démarrer.";
  } catch (e) {
    info.textContent = "Erreur chargement modèle: " + e.message;
    console.error(e);
  }
}

async function detectFrame() {
  if (!session || !isRunning) return;

  const start = performance.now();

  // Préparation input (640x640 RGB float32)
  canvas.width = video.videoWidth;
  canvas.height = video.videoHeight;
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  
  const { scale, padLeft, padTop } = letterbox(canvas.width, canvas.height);
  
  const input = new Float32Array(INPUT_SIZE * INPUT_SIZE * 3);
  let idx = 0;
  for (let y = 0; y < INPUT_SIZE; y++) {
    for (let x = 0; x < INPUT_SIZE; x++) {
      const px = Math.round((x - padLeft) / scale);
      const py = Math.round((y - padTop) / scale);
      if (px >= 0 && px < canvas.width && py >= 0 && py < canvas.height) {
        const i = (py * canvas.width + px) * 4;
        input[idx++] = imageData.data[i]   / 255; // R
        input[idx++] = imageData.data[i+1] / 255; // G
        input[idx++] = imageData.data[i+2] / 255; // B
      } else {
        idx += 3; // padding noir
      }
    }
  }

  const tensor = new ort.Tensor('float32', input, [1, 3, INPUT_SIZE, INPUT_SIZE]);

  // Inférence
  const feeds = { images: tensor };
  const results = await session.run(feeds);

  // Post-processing (YOLO format typique Ultralytics: [batch, num_boxes, 4+num_classes])
  const output = results[Object.keys(results)[0]].data; // premier output
  const numClasses = COCO_CLASSES.length;
  const boxes = [];

  for (let i = 0; i < output.length; i += 4 + numClasses) {
    const cx = output[i], cy = output[i+1], w = output[i+2], h = output[i+3];
    let maxScore = 0, maxCls = -1;
    for (let c = 0; c < numClasses; c++) {
      const score = output[i+4+c];
      if (score > maxScore) { maxScore = score; maxCls = c; }
    }
    if (maxScore > CONF_THRESHOLD) {
      boxes.push({
        xmin: (cx - w/2) * scale + padLeft,
        ymin: (cy - h/2) * scale + padTop,
        xmax: (cx + w/2) * scale + padLeft,
        ymax: (cy + h/2) * scale + padTop,
        score: maxScore,
        class: maxCls
      });
    }
  }

  const filtered = nms(boxes);

  // Dessin
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  ctx.strokeStyle = '#0f0';
  ctx.lineWidth = 3;
  ctx.font = '16px Arial';
  ctx.fillStyle = '#0f0';

  for (const b of filtered) {
    ctx.strokeRect(b.xmin, b.ymin, b.xmax - b.xmin, b.ymax - b.ymin);
    ctx.fillText(`${COCO_CLASSES[b.class]} ${(b.score*100).toFixed(0)}%`, b.xmin+5, b.ymin+20);
  }

  const fps = (1000 / (performance.now() - start)).toFixed(1);
  info.textContent = `Vision IA active • ${fps} FPS • ${filtered.length} objets`;

  requestAnimationFrame(detectFrame);
}

// === DÉMARRAGE ===
startBtn.onclick = async () => {
  startBtn.style.display = 'none';
  if (!navigator.mediaDevices?.getUserMedia) {
    info.textContent = "Caméra non supportée sur ce navigateur/appareil";
    return;
  }

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } }); // 'user' pour selfie
    video.srcObject = stream;
    await video.play();
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    isRunning = true;
    detectFrame();
  } catch (err) {
    info.textContent = "Erreur accès caméra: " + err.message;
  }
};

// Chargement initial
loadModel();
</script>
</body>
</html>
